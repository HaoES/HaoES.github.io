{
 "cells": [
  {
   "cell_type": "raw",
   "id": "d629eae5-374c-4cd6-9c38-a778f0e85eb4",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Create a LLM-powered Discord Bot\"\n",
    "author: \"Hamza\"\n",
    "date: \"2023-11-06\"\n",
    "categories: [llm, ml, nlp]\n",
    "image: \"logo.jpeg\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93b1c92-7585-43b8-bb07-4790422bcd31",
   "metadata": {},
   "source": [
    "In this blog post we are going to build an LLM-powered Discord Bot using `llama.cpp`, here are the steps we are going to follow:\n",
    "1. Download a LLM from huggingface \n",
    "2. Setup a REST API to use this model\n",
    "3. Create a Discord Bot Application \n",
    "4. Use the REST API to operate the bot\n",
    "\n",
    "This is a beginner friendly tutorial and assumes only basic knowledge of Python and Linux.\n",
    "I will be working in Ubuntu 20.04 installed on [WSL2](https://learn.microsoft.com/en-us/windows/wsl/install) but any other Linux distribution should work too."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62f3048-7cf1-4e82-a769-71f526fd2bd1",
   "metadata": {},
   "source": [
    "# 1. Prerequisites:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2eca6f-bac1-4af2-840f-ce08b3964d53",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.1 Tools:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bd30b3-452e-4893-98ba-b41f4632472c",
   "metadata": {},
   "source": [
    "Let's start first with an update to `apt` to get the latest metadata for Ubuntu packages.\n",
    "Open your Linux/WSL2 terminal and type the following command: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e0330c-9cd6-4220-af45-71199ff0fe0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sudo apt-get update"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b696c385-3780-48fb-b7e1-87666e3532eb",
   "metadata": {},
   "source": [
    "Now let's install some packages that we're going to need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60b021f-e0a0-4377-bb8f-4e914edecda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sudo apt-get install python3-virtualenv python3-pip curl jq "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdbb64a-7bb0-41f0-9074-f34a321ef0f9",
   "metadata": {},
   "source": [
    "- `virtualenv` is a tool to create isolated Python environments. It creates a folder which contains all the necessary executables to use the packages that a Python project would need. It's better to create a virtual environment for each project so that even if we mess up our installations, the mess wouldn't spread to all of the system.  \n",
    "- `pip` is the standard package manager for Python is pip . It allows you to install and manage packages that aren't part of the Python standard library. \n",
    "- `curl` curl (short for \"Client URL\") is a command line tool that enables data transfer over various network protocols. It communicates with a web or application server by specifying a relevant URL and the data that need to be sent or received.\n",
    "- `jq` is a lightweight and flexible command-line JSON processor that we will use to parse and format replies from our API.  \n",
    "Now that we installed `pip` let's install more tools that we're going to need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c6f8cc-3c7f-4ed6-9ad9-c8103ef96cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install discord.py python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0c99b9-b899-45b1-8030-ebb4c712f879",
   "metadata": {},
   "source": [
    "- `discord.py` is a Python library that exhaustively implements Discord's APIs in an efficient and Pythonic way. This includes utilizing Python's implementation of Async IO.\n",
    "- `python-dotenv` eads key-value pairs from a . env file and can set them as environment variables. It helps in the development of applications following the 12-factor principles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31bb56e-21b5-4769-b9e3-0bdfa3d73df5",
   "metadata": {},
   "source": [
    "## 1.2 The Model:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5c4442-4633-4a9c-bb7e-01bceae62e5d",
   "metadata": {},
   "source": [
    "We are going to use `llama.cpp` so you should download a model that is compatible with it. You can browse [HuggingFace](https://huggingface.co) and check the model card to see if it is compatible with `llama.cpp`. Another way is to download models with the `GGUF` extension.  \n",
    "\n",
    "I am going to be using the `Llama-2-7B-Chat-GGUF` by TheBloke available [here](https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGUF).  \n",
    "In the model card we can see that there are many versions of that model, the difference between each version is the quantisation method, you can see the size of each version and how much RAM it needs to operate. I downloaded the `llama-2-7b-chat.Q5_K_M.gguf` version.  \n",
    "\n",
    "To download a model you must go to the [Files and Versions Tab](https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGUF/tree/main) and right-click on the model you want then choose `Copy Link`.  \n",
    "Now type you can download using the `wget` command in the terminal like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a54e2a-d6aa-484a-8d86-e0c2f78d44f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "wget https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGUF/resolve/main/llama-2-7b-chat.Q5_K_M.gguf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea71e15-6c7c-4d4c-a96a-6fadffe4a121",
   "metadata": {},
   "source": [
    "If you don't have `wget` already installed, you can install it by simply typing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6ff986-0e25-450b-9b0f-fd2820328d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "sudo apt-get install wget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782b78e2-6cf9-4304-b94a-879006da2d7a",
   "metadata": {},
   "source": [
    "If you want a better quality of replies and also have the adequate hardware for it, you can download larger models (i.e. 13B and higher)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ee3bc8-73bf-4794-9b68-4c0aeeaa1380",
   "metadata": {},
   "source": [
    "## 1.3 Setting up the project files:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8b2ea1-220f-4bbc-b093-a3b2171b1193",
   "metadata": {},
   "source": [
    "Now let's create a directory for our project.  \n",
    "We can do that by the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b7706d-13ba-4d33-81df-6915a2dfa5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir discord-llm-bot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ad60ea-301c-4962-9354-3e063c89ad5f",
   "metadata": {},
   "source": [
    "Now let's access our newly created folder using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcb637d-4cab-44cb-a98f-4f8c73710dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd discord-llm-bot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d25a0bb-51ef-4d0b-b76f-76d9a2b2c83a",
   "metadata": {},
   "source": [
    "We create a virtual environment that we will call `env`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adeb520-bd70-4f39-b75b-dece7c8edde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "virtualenv env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d73d75-63ce-4380-8c4f-3ec86ddf2595",
   "metadata": {},
   "source": [
    "Once created, we need to activate our environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71896f61-797c-49b8-8087-3746b9e30b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "source env/bin/activate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b8b479-6976-40b3-9e86-f7a54a3f0ca9",
   "metadata": {},
   "source": [
    "You will see now that your terminal has a `(env)` it means that your virtual environment is active.  \n",
    "We will be using [Python bindings](https://github.com/abetlen/llama-cpp-python) for [LLAMA-CPP](https://github.com/ggerganov/llama.cpp). \n",
    "In the [Python bindings](https://github.com/abetlen/llama-cpp-python) page, go down to the `Web Server` section and use the following command to install the Python Bindings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebab7946-c662-46e2-8192-51bbc2915dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install \"llama-cpp-python[server]\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef762dc-f79b-4757-8f2b-6f8b4c53f245",
   "metadata": {},
   "source": [
    "# 2. Using the Model:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f50bc5-8c04-4c55-906a-6f12cf86b1c9",
   "metadata": {},
   "source": [
    "Now let's load our downloaded model. To do so we use the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbbf97e-970f-4249-9ffa-60b95e16475f",
   "metadata": {},
   "outputs": [],
   "source": [
    "python3 -m llama_cpp.server --model ~/llama-2-7b-chat.Q5_K_M.gguf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9fdf53-e564-40fd-b24e-17cc76311dbc",
   "metadata": {},
   "source": [
    "Here I am using the `llama-2-7b-chat.Q5_K_M.gguf` model, which I downloaded to my home folder hence the `~` in the path. So the command above must point to the `gguf` file of the model you downloaded.\n",
    "After running that command you should get a result on the terminal similar to this:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d751462-ae1c-4d9c-a17b-c2bce1f8e45d",
   "metadata": {},
   "source": [
    "```\n",
    "INFO:     Started server process [3414]\n",
    "INFO:     Waiting for application startup.\n",
    "INFO:     Application startup complete.\n",
    "INFO:     Uvicorn running on http://localhost:8000 (Press CTRL+C to quit)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7211f9-5890-4ca8-afa1-f9fb1881457d",
   "metadata": {},
   "source": [
    "Let's now navigate to [http://localhost:8000/docs](http://localhost:8000/docs) to the OpenAPI schemas.  \n",
    "Since we are building a ChatBot what interests us is the POST request for creating chat completion.  \n",
    "Click on `/v1/chat/completions` and copy the code from the `Example Value` field.\n",
    "\n",
    "The code is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b33e97-0381-4ded-a756-8209f9d1ca0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  \"messages\": [\n",
    "    {\n",
    "      \"content\": \"You are a helpful assistant.\",\n",
    "      \"role\": \"system\"\n",
    "    },\n",
    "    {\n",
    "      \"content\": \"What is the capital of France?\",\n",
    "      \"role\": \"user\"\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e003cd10-f9f4-4ff1-99ff-b15d7f41edca",
   "metadata": {},
   "source": [
    "Go back to your terminal and in a new tab (because the first one is still running your model, do not touch it) create a new file in your project directory, name it `payload.json`.  \n",
    "I use neovim, you can use your preferred text editor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077d1624-af68-4d62-88be-4ca67f4592ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "nvim payload.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73217e13-5316-4a49-8c49-cd1bb58fe6a2",
   "metadata": {},
   "source": [
    "paste the code you copied from the docs into the newly created `json` file, there are two message objects in the code we copied, one where the `role` is `system` and the other where the `role` is `user`.  \n",
    "We won't need the one for `system` since we are not aiming to modify the model's behavior so let's delete it.  \n",
    "The code should now look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4406eb56-d5b3-48f8-b49d-f2f48a8ae950",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  \"messages\": [\n",
    "    {\n",
    "      \"content\": \"What is the capital of France?\",\n",
    "      \"role\": \"user\"\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d81c26d-6365-455a-83ed-ab8bf7627f2b",
   "metadata": {},
   "source": [
    "for the `user` message we need the change the query string to match the prompt supported by our model, we can do this by adding `### Response: ` at the end of the `content` field.\n",
    "\n",
    "The code should look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035a34c9-aa71-4876-98be-d21d8a17bab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  \"messages\": [\n",
    "    {\n",
    "      \"content\": \"What is the capital of France? ### Response: \",\n",
    "      \"role\": \"user\"\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830a20d6-ce73-4b47-9512-55aed2872d92",
   "metadata": {},
   "source": [
    "We are good to go! Save and Close your file `ESC`+`:qw` if you are using vim/neovim ;)  \n",
    "Now let's test our model. \n",
    "Write the following command in the terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1e873e-2747-4c33-864f-a33b481fe9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "curl http://localhost:8000/v1/chat/completions -d @payload.json -H \"Content-Type: application/json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c0f92d-41db-4064-b9dd-f9e153bd2e22",
   "metadata": {},
   "source": [
    "It may take a while to give a result\n",
    "Then it should outputs you a response like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef29e64f-11bb-472a-b169-a3234bf373ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\"id\":\"chatcmpl-e219bd31-4515-4f1c-bc57-ea0d4e4f4907\",\"object\":\"chat.completion\",\"created\":1699287163,\"model\":\"/home/llama-2-7b-chat.Q5_K_M.gguf\",\"choices\":[{\"index\":0,\"message\":{\"role\":\"assistant\",\"content\":\" The capital of France is Paris.\"},\"finish_reason\":\"stop\"}],\"usage\":{\"prompt_tokens\":35,\"completion_tokens\":7,\"total_tokens\":42}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10fa557-f36e-4cbe-8192-d724177a53c6",
   "metadata": {},
   "source": [
    "It may take a while to give a result\n",
    "Then it should outputs you a response like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e62195-cbc2-4391-9e0e-a382a92aaedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\"id\":\"chatcmpl-e219bd31-4515-4f1c-bc57-ea0d4e4f4907\",\"object\":\"chat.completion\",\"created\":1699287163,\"model\":\"/home/llama-2-7b-chat.Q5_K_M.gguf\",\"choices\":[{\"index\":0,\"message\":{\"role\":\"assistant\",\"content\":\" The capital of France is Paris.\"},\"finish_reason\":\"stop\"}],\"usage\":{\"prompt_tokens\":35,\"completion_tokens\":7,\"total_tokens\":42}}%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1845f50-d241-44f3-922f-5c407486ba7a",
   "metadata": {},
   "source": [
    "We can see in the `content` field that our model got the right response `\" The capital of France is Paris.\"`  \n",
    "We can see this more clearly if we format the output of our model using `jq` by piping it at the end of the `curl` request like this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7aa4a88-4caf-450c-8822-41298e83493c",
   "metadata": {},
   "outputs": [],
   "source": [
    "curl http://localhost:8000/v1/chat/completions -d @payload.json -H \"Content-Type: application/json\" | jq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c67ef0-d057-4891-9c78-694a7a7ec1c8",
   "metadata": {},
   "source": [
    "You will get a better formatted and more readable result like this one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f469418f-93d5-4c54-aa07-0e64a0d7ca8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  \"id\": \"chatcmpl-a326fe62-8e64-4d12-b21d-84eecb18fe71\",\n",
    "  \"object\": \"chat.completion\",\n",
    "  \"created\": 1699287412,\n",
    "  \"model\": \"/home/llama-2-7b-chat.Q5_K_M.gguf\",\n",
    "  \"choices\": [\n",
    "    {\n",
    "      \"index\": 0,\n",
    "      \"message\": {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \" The capital of France is Paris.\"\n",
    "      },\n",
    "      \"finish_reason\": \"stop\"\n",
    "    }\n",
    "  ],\n",
    "  \"usage\": {\n",
    "    \"prompt_tokens\": 35,\n",
    "    \"completion_tokens\": 7,\n",
    "    \"total_tokens\": 42\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a94799b-2f18-4de8-8cd5-b62622e71091",
   "metadata": {},
   "source": [
    "Now let's ask it for something more complex, let's go back and edit our prompt in the `payload.json` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326bb213-026c-4a15-b2a9-673a8a9fbc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"content\": \"Tell me what quantum physics is about? ### Response: \",\n",
    "            \"role\": \"user\"\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5cca15-8f0b-4b23-9eab-c8fda2176bac",
   "metadata": {},
   "source": [
    "Save the file and run the same curl command again (use the up arrow in keyboard the retrieve old commands in the terminal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cd3b79-3dca-41bb-962d-03793ff6234e",
   "metadata": {},
   "outputs": [],
   "source": [
    "curl http://localhost:8000/v1/chat/completions -d @pl.json -H \"Content-Type: application/json\" | jq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9109515a-55d7-4ad6-bbd9-5e0cf9bbc32f",
   "metadata": {},
   "source": [
    "The output is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915ad17f-b20b-457b-8329-eaeb378dda4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  \"id\": \"chatcmpl-cadcbf3f-e72b-4934-b1c5-5e761547e9ef\",\n",
    "  \"object\": \"chat.completion\",\n",
    "  \"created\": 1699289318,\n",
    "  \"model\": \"/home/llama-2-7b-chat.Q5_K_M.gguf\",\n",
    "  \"choices\": [\n",
    "    {\n",
    "      \"index\": 0,\n",
    "      \"message\": {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \" Quantum physics, also known as quantum mechanics, is a branch of physics\"\n",
    "      },\n",
    "      \"finish_reason\": \"length\"\n",
    "    }\n",
    "  ],\n",
    "  \"usage\": {\n",
    "    \"prompt_tokens\": 37,\n",
    "    \"completion_tokens\": 16,\n",
    "    \"total_tokens\": 53\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430b6e70-e1af-48a4-8bce-90d3b5793a62",
   "metadata": {},
   "source": [
    "The reply that our model gave (which is found in the `content` field) is short, the model stopped before giving the whole answer, we can know the reason why by looking at the `finish_reason` field, we see that the reason is `length`.  \n",
    "This is due to the maximum token length which is set by default to 16.  \n",
    "We can change this in the body of the query by editing the `payload.json` like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50257078-235c-4818-8c64-d393bcbde405",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"max_tokens\":512,\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"content\": \"Tell me what quantum physics is about? ### Response: \",\n",
    "            \"role\": \"user\"\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d42250-3ac4-4ac5-86fe-3e15452d0671",
   "metadata": {},
   "source": [
    "Save and run the curl command again, now we have a longer (and much slower) response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e4cecc-f7c8-4676-9024-84e12a0aa944",
   "metadata": {},
   "outputs": [],
   "source": [
    "```\n",
    "{\n",
    "  \"id\": \"chatcmpl-17562ec9-6e71-4b0b-8057-b63db37b165f\",\n",
    "  \"object\": \"chat.completion\",\n",
    "  \"created\": 1699290401,\n",
    "  \"model\": \"/home/llama-2-7b-chat.Q5_K_M.gguf\",\n",
    "  \"choices\": [\n",
    "    {\n",
    "      \"index\": 0,\n",
    "      \"message\": {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \" Quantum physics, also known as quantum mechanics, is a branch of physics that explores the behavior of matter and energy at the smallest scales, at which the classical laws of physics no longer apply. At these scales, the principles of quantum mechanics govern the behavior of particles and systems, leading to phenomena such as superposition, entanglement, and wave-particle duality.\\nQuantum physics is based on the idea that particles, such as electrons and photons, can exist in multiple states simultaneously, a concept known as superposition. This means that a quantum particle can be in more than one place at the same time, or have more than one set of properties, such as spin or energy, at the same time.\\nAnother fundamental aspect of quantum physics is entanglement, which occurs when two or more particles become connected in such a way that their properties are correlated, regardless of the distance between them. This means that if something happens to one particle, it will instantly affect the other entangled particles, regardless of how far apart they are.\\nPerhaps one of the most counterintuitive aspects of quantum physics is wave-particle duality. According to this principle, particles can exhibit both wave-like and particle-like behavior depending on how they are observed. This means that a quantum particle can display properties of a wave, such as diffraction and interference, or properties of a particle, such as having definite position and momentum.\\nQuantum physics has many practical applications in technology, including transistors, lasers, and computer chips. It also has the potential to revolutionize fields such as medicine, energy production, and materials science. However, quantum physics is still an area of ongoing research and debate, with many unanswered questions and unresolved paradoxes.\\nIn summary, quantum physics is a branch of physics that explores the behavior of matter and energy at the smallest scales, where the classical laws of physics no longer apply. It is based on principles such as superposition, entanglement, and wave-particle duality, which lead to counterintuitive phenomena and have many practical applications in technology and other fields.\"\n",
    "      },\n",
    "      \"finish_reason\": \"stop\"\n",
    "    }\n",
    "  ],\n",
    "  \"usage\": {\n",
    "    \"prompt_tokens\": 37,\n",
    "    \"completion_tokens\": 453,\n",
    "    \"total_tokens\": 490\n",
    "  }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c63f1d-27a0-41d5-913f-c2d90c37c5c1",
   "metadata": {},
   "source": [
    "## 2.1 `chat.py` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fb9c41-79d5-4951-84db-e3666310e757",
   "metadata": {},
   "source": [
    "Writing `curl` requests each time is tedious, let's write a script to do make life easier for us:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54412e66-087e-4a32-bc18-e94fc9fab0f9",
   "metadata": {},
   "source": [
    "For our script we will use the [aiohttp](https://docs.aiohttp.org/en/stable/client_quickstart.html). The quickstart example is enough for what we want to do.  \n",
    "Let's copy the imports and the first example into our new script file that we will create in our project directory and we will call it `chat.py`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850b821c-f57c-43cf-84b1-e8af5a1f4529",
   "metadata": {},
   "outputs": [],
   "source": [
    "nvim chat.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b24952-055e-4a04-a09e-8c5b7038885c",
   "metadata": {},
   "source": [
    "Now when we paste the imports and first example our file is like that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3074dc47-b902-4c99-ae37-c7f0e5137d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiohttp\n",
    "import asyncio\n",
    "async def main():\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        async with session.get('http://httpbin.org/get') as resp:\n",
    "            print(resp.status)\n",
    "            print(await resp.text())\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15f3e62-b434-4afc-8070-36a997f59ee8",
   "metadata": {},
   "source": [
    "We must modify few things to make this work:\n",
    "First we create the following variables: must use a POST request instead of a GET request in line 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c454c0a-e479-4709-883e-cbb07cb4e019",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_URL = 'http://localhost:8000/v1/chat/completions'\n",
    "payload = {\n",
    "    \"max_tokens\":512,\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"content\": \"Tell me what quantum physics is about? ### Response: \",\n",
    "            \"role\": \"user\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "headers = {\"Content-Type\":\"application/json\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64c7d72-95c9-459f-a830-722cb66c2069",
   "metadata": {},
   "source": [
    "Then we need to use a POST request instead of a GET request and we also need to specify our `API_URL`, `headers`, and `payload` like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f728e12-eccf-416c-8835-34795357d9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "async with session.get(API_URL, data = payload, headers = headers) as resp:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8558faef-d949-4342-bd68-d93fcaa23496",
   "metadata": {},
   "source": [
    "Now in order for our payload to get parsed correctly we need to dump it as a string for the data argument so we `import json` and use `data = json.dumps(payload)` method to do so.\n",
    "\n",
    "Our `chat.py` should look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2731be3d-3fce-43e3-9a0d-673953276610",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import aiohttp\n",
    "import asyncio\n",
    "API_URL = 'http://localhost:8000/v1/chat/completions'\n",
    "payload = {\n",
    "    \"max_tokens\":512,\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"content\": \"What is the Capital of Japan? ### Response: \",\n",
    "            \"role\": \"user\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "headers = {\"Content-Type\":\"application/json\"}\n",
    "\n",
    "async def main():\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        async with session.post(API_URL, data = json.dumps(payload), headers = headers) as resp:\n",
    "            print(resp.status)\n",
    "            print(await resp.text())\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b4b073-0cef-4cf1-919d-0013dca4c413",
   "metadata": {},
   "source": [
    "(I changed the prompt because the one about Quantum Physics takes so much time to respond.)\n",
    "let's save it and run it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a6da68-8f4d-468b-9cba-baae4efbf936",
   "metadata": {},
   "outputs": [],
   "source": [
    "python3 chat.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73aa9ea-f07f-40cb-8b7c-57b93c919a96",
   "metadata": {},
   "source": [
    "this gives us the following result:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11733a83-4589-4b81-b29a-99932dc0aab3",
   "metadata": {},
   "source": [
    "```\n",
    "{\"id\":\"chatcmpl-f619a4ee-8509-4029-8b31-20b65db84ffd\",\"object\":\"chat.completion\",\"created\":1699293282,\"model\":\"/home/llama-2-7b-chat.Q5_K_M.gguf\",\"choices\":[{\"index\":0,\"message\":{\"role\":\"assistant\",\"content\":\" The capital of Japan is Tokyo.\"},\"finish_reason\":\"stop\"}],\"usage\":{\"prompt_tokens\":35,\"completion_tokens\":7,\"total_tokens\":42}}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11998167-44be-4bbc-a956-20864759fc25",
   "metadata": {},
   "source": [
    "Let's modify our script to print just the desired reply and also so that we don't have to edit our script each time we want to use a different prompt. \n",
    "\n",
    "Let's first see what the script would look like and then explain our changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a06012-2c7a-4cc4-bd78-61195a1c4358",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import aiohttp\n",
    "import asyncio\n",
    "\n",
    "API_URL = 'http://localhost:8000/v1/chat/completions'\n",
    "headers = {\"Content-Type\":\"application/json\"}\n",
    "\n",
    "async def main():\n",
    "    prompt = input(\"User: \")\n",
    "    payload = {\n",
    "        \"max_tokens\":512,\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"content\": f\"{prompt} ### response: \",\n",
    "                \"role\": \"user\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        async with session.post(API_URL, data = json.dumps(payload), headers = headers) as resp:\n",
    "            reply = await resp.json()\n",
    "            reply_content = reply[\"choices\"][0][\"message\"][\"content\"]\n",
    "            print(reply_content)\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f82c09-ca6c-4d2f-9c0e-a15aa701d87c",
   "metadata": {},
   "source": [
    "- First we moved the `payload` variable into the `main()` function.\n",
    "- Then we created a new variable `prompt` that takes the input of the User and uses it as a prompt, you can see that this variable is used in the `content` field of the `payload` (line 14).\n",
    "- We modified the print statement in the `session` (line 21), it is now a variable called `reply`, this variable contains the whole reply.\n",
    "- We proceed to take only what matters to us (line 22) which is the text in the `content` field, and we put it in the `reply_content` variable.  \n",
    "Now let's save `chat.py` and run it again with `python3 chat.py`  \n",
    "I gave it the prompt `Give me 3 ancient African cities` and the output was:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede971b1-0b01-4170-9ad1-e316f25b13dc",
   "metadata": {},
   "source": [
    "```\n",
    " Sure! Here are three ancient African cities that were important centers of trade, culture, and civilization:\n",
    "\n",
    "1. Memphis, Egypt - Founded around 2925 BCE by the pharaoh Narmer, Memphis was the capital of ancient Egypt and one of the most important cities in the ancient world. It was located on the west bank of the Nile River and was known for its impressive architecture, including the Great Sphinx and the Pyramids of Giza.\n",
    "2. Axum, Ethiopia - Axum was a major center of trade and commerce in ancient Africa, located in what is now modern-day Ethiopia. Founded around 100 CE, it was known for its advanced agriculture, architecture, and engineering. The city was also an important hub for the spread of Christianity throughout East Africa.\n",
    "3. Timbuktu, Mali - Located in what is now modern-day Mali, Timbuktu was a major center of trade and learning in West Africa during the medieval period. Founded around 1100 CE, it was known for its universities and libraries, which were renowned throughout the Islamic world. The city was also an important center for the production of books and manuscripts.\n",
    "These three cities were all major centers of trade, culture, and civilization in their respective regions during ancient times, and they played important roles in shaping the history of Africa and the wider world.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cdff76-725b-4163-be14-fe085fde4ee6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
