{
 "cells": [
  {
   "cell_type": "raw",
   "id": "d629eae5-374c-4cd6-9c38-a778f0e85eb4",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Create a LLM-powered Discord Bot\"\n",
    "author: \"Hamza\"\n",
    "date: \"2023-11-07\"\n",
    "categories: [llm, ml, nlp]\n",
    "image: \"logo.jpeg\"\n",
    "format:\n",
    "  html:\n",
    "    code-line-numbers: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93b1c92-7585-43b8-bb07-4790422bcd31",
   "metadata": {},
   "source": [
    "In this beginner friendly blog post we are going to build an LLM-powered Discord Bot using `llama.cpp`, here are the steps we are going to follow:\n",
    "1. Download a LLM from huggingface \n",
    "2. Setup a REST API to use this model\n",
    "3. Create a Discord Bot Application \n",
    "4. Use the REST API to operate the bot\n",
    "\n",
    "This is a beginner friendly tutorial and assumes only basic knowledge of Python and Linux.\n",
    "I will be working in Ubuntu 20.04 installed on [WSL2](https://learn.microsoft.com/en-us/windows/wsl/install) but any other Linux distribution should work too."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62f3048-7cf1-4e82-a769-71f526fd2bd1",
   "metadata": {},
   "source": [
    "# 1. Prerequisites:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2eca6f-bac1-4af2-840f-ce08b3964d53",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.1 Tools:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bd30b3-452e-4893-98ba-b41f4632472c",
   "metadata": {},
   "source": [
    "Let's start first with an update to `apt` to get the latest metadata for Ubuntu packages.\n",
    "Open your Linux/WSL2 terminal and type the following command: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e0330c-9cd6-4220-af45-71199ff0fe0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sudo apt-get update"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b696c385-3780-48fb-b7e1-87666e3532eb",
   "metadata": {},
   "source": [
    "Now let's install some packages that we're going to need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60b021f-e0a0-4377-bb8f-4e914edecda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sudo apt-get install python3-virtualenv python3-pip curl jq "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdbb64a-7bb0-41f0-9074-f34a321ef0f9",
   "metadata": {},
   "source": [
    "- `virtualenv` is a tool to create isolated Python environments. It creates a folder which contains all the necessary executables to use the packages that a Python project would need. It's better to create a virtual environment for each project so that even if we mess up our installations, the mess wouldn't spread to all of the system.  \n",
    "- `pip` is the standard package manager for Python is pip . It allows you to install and manage packages that aren't part of the Python standard library. \n",
    "- `curl` curl (short for \"Client URL\") is a command line tool that enables data transfer over various network protocols. It communicates with a web or application server by specifying a relevant URL and the data that need to be sent or received.\n",
    "- `jq` is a lightweight and flexible command-line JSON processor that we will use to parse and format replies from our API.  \n",
    "Now that we installed `pip` let's install more tools that we're going to need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c6f8cc-3c7f-4ed6-9ad9-c8103ef96cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install discord.py python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0c99b9-b899-45b1-8030-ebb4c712f879",
   "metadata": {},
   "source": [
    "- `discord.py` is a Python library that exhaustively implements Discord's APIs in an efficient and Pythonic way. This includes utilizing Python's implementation of Async IO.\n",
    "- `python-dotenv` eads key-value pairs from a . env file and can set them as environment variables. It helps in the development of applications following the 12-factor principles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31bb56e-21b5-4769-b9e3-0bdfa3d73df5",
   "metadata": {},
   "source": [
    "## 1.2 The Model:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5c4442-4633-4a9c-bb7e-01bceae62e5d",
   "metadata": {},
   "source": [
    "We are going to use `llama.cpp` so you should download a model that is compatible with it. You can browse [HuggingFace](https://huggingface.co) and check the model card to see if it is compatible with `llama.cpp`. Another way is to download models with the `GGUF` extension.  \n",
    "\n",
    "I am going to be using the `Llama-2-7B-Chat-GGUF` by TheBloke available [here](https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGUF).  \n",
    "In the model card we can see that there are many versions of that model, the difference between each version is the quantisation method, you can see the size of each version and how much RAM it needs to operate. I downloaded the `llama-2-7b-chat.Q5_K_M.gguf` version.  \n",
    "\n",
    "To download a model you must go to the [Files and Versions Tab](https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGUF/tree/main) and right-click on the model you want then choose `Copy Link`.  \n",
    "Now type you can download using the `wget` command in the terminal like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a54e2a-d6aa-484a-8d86-e0c2f78d44f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "wget https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGUF/resolve/main/llama-2-7b-chat.Q5_K_M.gguf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea71e15-6c7c-4d4c-a96a-6fadffe4a121",
   "metadata": {},
   "source": [
    "If you don't have `wget` already installed, you can install it by simply typing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6ff986-0e25-450b-9b0f-fd2820328d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "sudo apt-get install wget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782b78e2-6cf9-4304-b94a-879006da2d7a",
   "metadata": {},
   "source": [
    "If you want a better quality of replies and also have the adequate hardware for it, you can download larger models (i.e. 13B and higher)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ee3bc8-73bf-4794-9b68-4c0aeeaa1380",
   "metadata": {},
   "source": [
    "## 1.3 Setting up the project files:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8b2ea1-220f-4bbc-b093-a3b2171b1193",
   "metadata": {},
   "source": [
    "Now let's create a directory for our project.  \n",
    "We can do that by the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b7706d-13ba-4d33-81df-6915a2dfa5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir discord-llm-bot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ad60ea-301c-4962-9354-3e063c89ad5f",
   "metadata": {},
   "source": [
    "Now let's access our newly created folder using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcb637d-4cab-44cb-a98f-4f8c73710dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd discord-llm-bot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d25a0bb-51ef-4d0b-b76f-76d9a2b2c83a",
   "metadata": {},
   "source": [
    "We create a virtual environment that we will call `env`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adeb520-bd70-4f39-b75b-dece7c8edde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "virtualenv env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d73d75-63ce-4380-8c4f-3ec86ddf2595",
   "metadata": {},
   "source": [
    "Once created, we need to activate our environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71896f61-797c-49b8-8087-3746b9e30b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "source env/bin/activate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b8b479-6976-40b3-9e86-f7a54a3f0ca9",
   "metadata": {},
   "source": [
    "You will see now that your terminal has a `(env)` it means that your virtual environment is active.  \n",
    "We will be using [Python bindings](https://github.com/abetlen/llama-cpp-python) for [LLAMA-CPP](https://github.com/ggerganov/llama.cpp). \n",
    "In the [Python bindings](https://github.com/abetlen/llama-cpp-python) page, go down to the `Web Server` section and use the following command to install the Python Bindings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebab7946-c662-46e2-8192-51bbc2915dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install \"llama-cpp-python[server]\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef762dc-f79b-4757-8f2b-6f8b4c53f245",
   "metadata": {},
   "source": [
    "# 2. Using the Model:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f50bc5-8c04-4c55-906a-6f12cf86b1c9",
   "metadata": {},
   "source": [
    "Now let's load our downloaded model. To do so we use the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbbf97e-970f-4249-9ffa-60b95e16475f",
   "metadata": {},
   "outputs": [],
   "source": [
    "python3 -m llama_cpp.server --model ~/llama-2-7b-chat.Q5_K_M.gguf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9fdf53-e564-40fd-b24e-17cc76311dbc",
   "metadata": {},
   "source": [
    "Here I am using the `llama-2-7b-chat.Q5_K_M.gguf` model, which I downloaded to my home folder hence the `~` in the path. So the command above must point to the `gguf` file of the model you downloaded.\n",
    "After running that command you should get a result on the terminal similar to this:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d751462-ae1c-4d9c-a17b-c2bce1f8e45d",
   "metadata": {},
   "source": [
    "```\n",
    "INFO:     Started server process [3414]\n",
    "INFO:     Waiting for application startup.\n",
    "INFO:     Application startup complete.\n",
    "INFO:     Uvicorn running on http://localhost:8000 (Press CTRL+C to quit)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7211f9-5890-4ca8-afa1-f9fb1881457d",
   "metadata": {},
   "source": [
    "Let's now navigate to [http://localhost:8000/docs](http://localhost:8000/docs) to the OpenAPI schemas.  \n",
    "Since we are building a ChatBot what interests us is the POST request for creating chat completion.  \n",
    "Click on `/v1/chat/completions` and copy the code from the `Example Value` field.\n",
    "\n",
    "The code is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b33e97-0381-4ded-a756-8209f9d1ca0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  \"messages\": [\n",
    "    {\n",
    "      \"content\": \"You are a helpful assistant.\",\n",
    "      \"role\": \"system\"\n",
    "    },\n",
    "    {\n",
    "      \"content\": \"What is the capital of France?\",\n",
    "      \"role\": \"user\"\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e003cd10-f9f4-4ff1-99ff-b15d7f41edca",
   "metadata": {},
   "source": [
    "Go back to your terminal and in a new tab (because the first one is still running your model, do not touch it) create a new file in your project directory, name it `payload.json`.  \n",
    "I use neovim, you can use your preferred text editor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077d1624-af68-4d62-88be-4ca67f4592ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "nvim payload.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73217e13-5316-4a49-8c49-cd1bb58fe6a2",
   "metadata": {},
   "source": [
    "paste the code you copied from the docs into the newly created `json` file, there are two message objects in the code we copied, one where the `role` is `system` and the other where the `role` is `user`.  \n",
    "We won't need the one for `system` since we are not aiming to modify the model's behavior so let's delete it.  \n",
    "The code should now look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4406eb56-d5b3-48f8-b49d-f2f48a8ae950",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  \"messages\": [\n",
    "    {\n",
    "      \"content\": \"What is the capital of France?\",\n",
    "      \"role\": \"user\"\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d81c26d-6365-455a-83ed-ab8bf7627f2b",
   "metadata": {},
   "source": [
    "for the `user` message we need the change the query string to match the prompt supported by our model, we can do this by adding `### Response: ` at the end of the `content` field.\n",
    "\n",
    "The code should look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035a34c9-aa71-4876-98be-d21d8a17bab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  \"messages\": [\n",
    "    {\n",
    "      \"content\": \"What is the capital of France? ### Response: \",\n",
    "      \"role\": \"user\"\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830a20d6-ce73-4b47-9512-55aed2872d92",
   "metadata": {},
   "source": [
    "We are good to go! Save and Close your file `ESC`+`:qw` if you are using vim/neovim ;)  \n",
    "Now let's test our model. \n",
    "Write the following command in the terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1e873e-2747-4c33-864f-a33b481fe9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "curl http://localhost:8000/v1/chat/completions -d @payload.json -H \"Content-Type: application/json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c0f92d-41db-4064-b9dd-f9e153bd2e22",
   "metadata": {},
   "source": [
    "It may take a while to give a result\n",
    "Then it should outputs you a response like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef29e64f-11bb-472a-b169-a3234bf373ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\"id\":\"chatcmpl-e219bd31-4515-4f1c-bc57-ea0d4e4f4907\",\"object\":\"chat.completion\",\"created\":1699287163,\"model\":\"/home/llama-2-7b-chat.Q5_K_M.gguf\",\"choices\":[{\"index\":0,\"message\":{\"role\":\"assistant\",\"content\":\" The capital of France is Paris.\"},\"finish_reason\":\"stop\"}],\"usage\":{\"prompt_tokens\":35,\"completion_tokens\":7,\"total_tokens\":42}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10fa557-f36e-4cbe-8192-d724177a53c6",
   "metadata": {},
   "source": [
    "It may take a while to give a result\n",
    "Then it should outputs you a response like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e62195-cbc2-4391-9e0e-a382a92aaedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\"id\":\"chatcmpl-e219bd31-4515-4f1c-bc57-ea0d4e4f4907\",\"object\":\"chat.completion\",\"created\":1699287163,\"model\":\"/home/llama-2-7b-chat.Q5_K_M.gguf\",\"choices\":[{\"index\":0,\"message\":{\"role\":\"assistant\",\"content\":\" The capital of France is Paris.\"},\"finish_reason\":\"stop\"}],\"usage\":{\"prompt_tokens\":35,\"completion_tokens\":7,\"total_tokens\":42}}%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1845f50-d241-44f3-922f-5c407486ba7a",
   "metadata": {},
   "source": [
    "We can see in the `content` field that our model got the right response `\" The capital of France is Paris.\"`  \n",
    "We can see this more clearly if we format the output of our model using `jq` by piping it at the end of the `curl` request like this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7aa4a88-4caf-450c-8822-41298e83493c",
   "metadata": {},
   "outputs": [],
   "source": [
    "curl http://localhost:8000/v1/chat/completions -d @payload.json -H \"Content-Type: application/json\" | jq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c67ef0-d057-4891-9c78-694a7a7ec1c8",
   "metadata": {},
   "source": [
    "You will get a better formatted and more readable result like this one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f469418f-93d5-4c54-aa07-0e64a0d7ca8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  \"id\": \"chatcmpl-a326fe62-8e64-4d12-b21d-84eecb18fe71\",\n",
    "  \"object\": \"chat.completion\",\n",
    "  \"created\": 1699287412,\n",
    "  \"model\": \"/home/llama-2-7b-chat.Q5_K_M.gguf\",\n",
    "  \"choices\": [\n",
    "    {\n",
    "      \"index\": 0,\n",
    "      \"message\": {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \" The capital of France is Paris.\"\n",
    "      },\n",
    "      \"finish_reason\": \"stop\"\n",
    "    }\n",
    "  ],\n",
    "  \"usage\": {\n",
    "    \"prompt_tokens\": 35,\n",
    "    \"completion_tokens\": 7,\n",
    "    \"total_tokens\": 42\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a94799b-2f18-4de8-8cd5-b62622e71091",
   "metadata": {},
   "source": [
    "Now let's ask it for something more complex, let's go back and edit our prompt in the `payload.json` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326bb213-026c-4a15-b2a9-673a8a9fbc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"content\": \"Tell me what quantum physics is about? ### Response: \",\n",
    "            \"role\": \"user\"\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5cca15-8f0b-4b23-9eab-c8fda2176bac",
   "metadata": {},
   "source": [
    "Save the file and run the same curl command again (use the up arrow in keyboard the retrieve old commands in the terminal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cd3b79-3dca-41bb-962d-03793ff6234e",
   "metadata": {},
   "outputs": [],
   "source": [
    "curl http://localhost:8000/v1/chat/completions -d @pl.json -H \"Content-Type: application/json\" | jq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9109515a-55d7-4ad6-bbd9-5e0cf9bbc32f",
   "metadata": {},
   "source": [
    "The output is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915ad17f-b20b-457b-8329-eaeb378dda4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  \"id\": \"chatcmpl-cadcbf3f-e72b-4934-b1c5-5e761547e9ef\",\n",
    "  \"object\": \"chat.completion\",\n",
    "  \"created\": 1699289318,\n",
    "  \"model\": \"/home/llama-2-7b-chat.Q5_K_M.gguf\",\n",
    "  \"choices\": [\n",
    "    {\n",
    "      \"index\": 0,\n",
    "      \"message\": {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \" Quantum physics, also known as quantum mechanics, is a branch of physics\"\n",
    "      },\n",
    "      \"finish_reason\": \"length\"\n",
    "    }\n",
    "  ],\n",
    "  \"usage\": {\n",
    "    \"prompt_tokens\": 37,\n",
    "    \"completion_tokens\": 16,\n",
    "    \"total_tokens\": 53\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430b6e70-e1af-48a4-8bce-90d3b5793a62",
   "metadata": {},
   "source": [
    "The reply that our model gave (which is found in the `content` field) is short, the model stopped before giving the whole answer, we can know the reason why by looking at the `finish_reason` field, we see that the reason is `length`.  \n",
    "This is due to the maximum token length which is set by default to 16.  \n",
    "We can change this in the body of the query by editing the `payload.json` like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50257078-235c-4818-8c64-d393bcbde405",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"max_tokens\":512,\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"content\": \"Tell me what quantum physics is about? ### Response: \",\n",
    "            \"role\": \"user\"\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d42250-3ac4-4ac5-86fe-3e15452d0671",
   "metadata": {},
   "source": [
    "Save and run the curl command again, now we have a longer (and much slower) response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e4cecc-f7c8-4676-9024-84e12a0aa944",
   "metadata": {},
   "outputs": [],
   "source": [
    "```\n",
    "{\n",
    "  \"id\": \"chatcmpl-17562ec9-6e71-4b0b-8057-b63db37b165f\",\n",
    "  \"object\": \"chat.completion\",\n",
    "  \"created\": 1699290401,\n",
    "  \"model\": \"/home/llama-2-7b-chat.Q5_K_M.gguf\",\n",
    "  \"choices\": [\n",
    "    {\n",
    "      \"index\": 0,\n",
    "      \"message\": {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \" Quantum physics, also known as quantum mechanics, is a branch of physics that explores the behavior of matter and energy at the smallest scales, at which the classical laws of physics no longer apply. At these scales, the principles of quantum mechanics govern the behavior of particles and systems, leading to phenomena such as superposition, entanglement, and wave-particle duality.\\nQuantum physics is based on the idea that particles, such as electrons and photons, can exist in multiple states simultaneously, a concept known as superposition. This means that a quantum particle can be in more than one place at the same time, or have more than one set of properties, such as spin or energy, at the same time.\\nAnother fundamental aspect of quantum physics is entanglement, which occurs when two or more particles become connected in such a way that their properties are correlated, regardless of the distance between them. This means that if something happens to one particle, it will instantly affect the other entangled particles, regardless of how far apart they are.\\nPerhaps one of the most counterintuitive aspects of quantum physics is wave-particle duality. According to this principle, particles can exhibit both wave-like and particle-like behavior depending on how they are observed. This means that a quantum particle can display properties of a wave, such as diffraction and interference, or properties of a particle, such as having definite position and momentum.\\nQuantum physics has many practical applications in technology, including transistors, lasers, and computer chips. It also has the potential to revolutionize fields such as medicine, energy production, and materials science. However, quantum physics is still an area of ongoing research and debate, with many unanswered questions and unresolved paradoxes.\\nIn summary, quantum physics is a branch of physics that explores the behavior of matter and energy at the smallest scales, where the classical laws of physics no longer apply. It is based on principles such as superposition, entanglement, and wave-particle duality, which lead to counterintuitive phenomena and have many practical applications in technology and other fields.\"\n",
    "      },\n",
    "      \"finish_reason\": \"stop\"\n",
    "    }\n",
    "  ],\n",
    "  \"usage\": {\n",
    "    \"prompt_tokens\": 37,\n",
    "    \"completion_tokens\": 453,\n",
    "    \"total_tokens\": 490\n",
    "  }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c63f1d-27a0-41d5-913f-c2d90c37c5c1",
   "metadata": {},
   "source": [
    "## 2.1 `chat.py` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fb9c41-79d5-4951-84db-e3666310e757",
   "metadata": {},
   "source": [
    "Writing `curl` requests each time is tedious, let's write a script to do make life easier for us:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54412e66-087e-4a32-bc18-e94fc9fab0f9",
   "metadata": {},
   "source": [
    "For our script we will use the [aiohttp](https://docs.aiohttp.org/en/stable/client_quickstart.html). The quickstart example is enough for what we want to do.  \n",
    "Let's copy the imports and the first example into our new script file that we will create in our project directory and we will call it `chat.py`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850b821c-f57c-43cf-84b1-e8af5a1f4529",
   "metadata": {},
   "outputs": [],
   "source": [
    "nvim chat.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b24952-055e-4a04-a09e-8c5b7038885c",
   "metadata": {},
   "source": [
    "Now when we paste the imports and first example our file is like that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3074dc47-b902-4c99-ae37-c7f0e5137d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiohttp\n",
    "import asyncio\n",
    "async def main():\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        async with session.get('http://httpbin.org/get') as resp:\n",
    "            print(resp.status)\n",
    "            print(await resp.text())\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15f3e62-b434-4afc-8070-36a997f59ee8",
   "metadata": {},
   "source": [
    "We must modify few things to make this work:\n",
    "First we create the following variables: must use a POST request instead of a GET request in line 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c454c0a-e479-4709-883e-cbb07cb4e019",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_URL = 'http://localhost:8000/v1/chat/completions'\n",
    "payload = {\n",
    "    \"max_tokens\":512,\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"content\": \"Tell me what quantum physics is about? ### Response: \",\n",
    "            \"role\": \"user\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "headers = {\"Content-Type\":\"application/json\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64c7d72-95c9-459f-a830-722cb66c2069",
   "metadata": {},
   "source": [
    "Then we need to use a POST request instead of a GET request and we also need to specify our `API_URL`, `headers`, and `payload` like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f728e12-eccf-416c-8835-34795357d9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "async with session.get(API_URL, data = payload, headers = headers) as resp:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8558faef-d949-4342-bd68-d93fcaa23496",
   "metadata": {},
   "source": [
    "Now in order for our payload to get parsed correctly we need to dump it as a string for the data argument so we `import json` and use `data = json.dumps(payload)` method to do so.\n",
    "\n",
    "Our `chat.py` should look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2731be3d-3fce-43e3-9a0d-673953276610",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import aiohttp\n",
    "import asyncio\n",
    "API_URL = 'http://localhost:8000/v1/chat/completions'\n",
    "payload = {\n",
    "    \"max_tokens\":512,\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"content\": \"What is the Capital of Japan? ### Response: \",\n",
    "            \"role\": \"user\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "headers = {\"Content-Type\":\"application/json\"}\n",
    "\n",
    "async def main():\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        async with session.post(API_URL, data = json.dumps(payload), headers = headers) as resp:\n",
    "            print(resp.status)\n",
    "            print(await resp.text())\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b4b073-0cef-4cf1-919d-0013dca4c413",
   "metadata": {},
   "source": [
    "(I changed the prompt because the one about Quantum Physics takes so much time to respond.)\n",
    "let's save it and run it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a6da68-8f4d-468b-9cba-baae4efbf936",
   "metadata": {},
   "outputs": [],
   "source": [
    "python3 chat.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73aa9ea-f07f-40cb-8b7c-57b93c919a96",
   "metadata": {},
   "source": [
    "this gives us the following result:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8be40a-6a06-4edd-a7ef-55237c2bfe95",
   "metadata": {},
   "source": [
    "```{\"id\":\"chatcmpl-f619a4ee-8509-4029-8b31-20b65db84ffd\",\"object\":\"chat.completion\",\"created\":1699293282,\"model\":\"/home/llama-2-7b-chat.Q5_K_M.gguf\",\"choices\":[{\"index\":0,\"message\":{\"role\":\"assistant\",\"content\":\" The capital of Japan is Tokyo.\"},\"finish_reason\":\"stop\"}],\"usage\":{\"prompt_tokens\":35,\"completion_tokens\":7,\"total_tokens\":42}}```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11998167-44be-4bbc-a956-20864759fc25",
   "metadata": {},
   "source": [
    "Let's modify our script to print just the desired reply and also so that we don't have to edit our script each time we want to use a different prompt. \n",
    "\n",
    "Let's first see what the script would look like and then explain our changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a06012-2c7a-4cc4-bd78-61195a1c4358",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import aiohttp\n",
    "import asyncio\n",
    "\n",
    "API_URL = 'http://localhost:8000/v1/chat/completions'\n",
    "headers = {\"Content-Type\":\"application/json\"}\n",
    "\n",
    "async def main():\n",
    "    prompt = input(\"User: \")\n",
    "    payload = {\n",
    "        \"max_tokens\":512,\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"content\": f\"{prompt} ### response: \",\n",
    "                \"role\": \"user\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        async with session.post(API_URL, data = json.dumps(payload), headers = headers) as resp:\n",
    "            reply = await resp.json()\n",
    "            reply_content = reply[\"choices\"][0][\"message\"][\"content\"]\n",
    "            print(reply_content)\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f82c09-ca6c-4d2f-9c0e-a15aa701d87c",
   "metadata": {},
   "source": [
    "- First we moved the `payload` variable into the `main()` function.\n",
    "- Then we created a new variable `prompt` that takes the input of the User and uses it as a prompt, you can see that this variable is used in the `content` field of the `payload` (line 14).\n",
    "- We modified the print statement in the `session` (line 21), it is now a variable called `reply`, this variable contains the whole reply.\n",
    "- We proceed to take only what matters to us (line 22) which is the text in the `content` field, and we put it in the `reply_content` variable.  \n",
    "Now let's save `chat.py` and run it again with `python3 chat.py`  \n",
    "I gave it the prompt `Give me 3 ancient African cities` and the output was:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede971b1-0b01-4170-9ad1-e316f25b13dc",
   "metadata": {},
   "source": [
    "```\n",
    " Sure! Here are three ancient African cities that were important centers of trade, culture, and civilization:\n",
    "\n",
    "1. Memphis, Egypt - Founded around 2925 BCE by the pharaoh Narmer, Memphis was the capital of ancient Egypt and one of the most important cities in the ancient world. It was located on the west bank of the Nile River and was known for its impressive architecture, including the Great Sphinx and the Pyramids of Giza.\n",
    "2. Axum, Ethiopia - Axum was a major center of trade and commerce in ancient Africa, located in what is now modern-day Ethiopia. Founded around 100 CE, it was known for its advanced agriculture, architecture, and engineering. The city was also an important hub for the spread of Christianity throughout East Africa.\n",
    "3. Timbuktu, Mali - Located in what is now modern-day Mali, Timbuktu was a major center of trade and learning in West Africa during the medieval period. Founded around 1100 CE, it was known for its universities and libraries, which were renowned throughout the Islamic world. The city was also an important center for the production of books and manuscripts.\n",
    "These three cities were all major centers of trade, culture, and civilization in their respective regions during ancient times, and they played important roles in shaping the history of Africa and the wider world.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d69b3b-5718-4d5b-a044-106b801c8a09",
   "metadata": {},
   "source": [
    "## 2.2 Having a conversation:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42ebd0e-f20f-42b4-820e-7f0934323623",
   "metadata": {},
   "source": [
    "When you run `chat.py` you will remark that the conversation ends after the first response, this is not ideal for a chatbot. Let's modify `chat.py` to have longer conversations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d277f7-a17b-4c7c-a4c3-2e592fd22a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import aiohttp\n",
    "import asyncio\n",
    "\n",
    "API_URL = 'http://localhost:8000/v1/chat/completions'\n",
    "headers = {\"Content-Type\":\"application/json\"}\n",
    "\n",
    "async def main():\n",
    "    while True:\n",
    "        prompt = input(\"User: \")\n",
    "        payload = {\n",
    "        \"max_tokens\":512,\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"content\": f\"{prompt} ### response: \",\n",
    "                \"role\": \"user\"\n",
    "            }\n",
    "                    ]\n",
    "        }\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            async with session.post(API_URL, data = json.dumps(payload), headers = headers) as resp:\n",
    "                reply = await resp.json()\n",
    "                reply_content = reply[\"choices\"][0][\"message\"][\"content\"]\n",
    "                print(f\"Bot: {reply_content}\")\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6a0cc5-f93d-499f-85c6-d0badf367159",
   "metadata": {},
   "source": [
    "We wrapped our code in a `while` statement so that we can maintain a conversation for as long as we desire, we also modified the `print` statement of the reply to show that it's the Bot talking.  \n",
    "Now run `chat.py` again and you can chat as long as you want. You can use `CTRL + C` to terminate the program. \n",
    "Here is an example of chat session I had with the bot:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c331ac-90f8-41f5-9f34-8c9d3326efff",
   "metadata": {},
   "source": [
    "```\n",
    "User: What is the largest city in Africa?\n",
    "Bot:  The largest city in Africa is Lagos, Nigeria. With a population of over 21 million people, Lagos is not only the largest city in Africa but also one of the fastest-growing cities in the world. It is located in the southwestern part of Nigeria and is known for its vibrant culture, diverse economy, and rich history.\n",
    "User: What is the second largest one?\n",
    "Bot:  The second largest planet in our solar system is Jupiter.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12595daa-c77a-4c39-bd16-bbd11bf2b090",
   "metadata": {},
   "source": [
    "As you can see we can now chat with our Bot but unfortunately he can't keep track of the context of the conversation. Let's fix that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59566766-8803-4f09-9c80-bf1c679ea46e",
   "metadata": {},
   "source": [
    "## 2.3 Handling context:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c49648-334e-4532-b81e-f7806e451fd8",
   "metadata": {},
   "source": [
    "Our model is not following the context of the conversation, this is because the OpenAPI implementation (which we are using here) requires the whole conversation to be passed as a prompt in each request. You can read more about this [here](https://platform.openai.com/docs/api-reference/chat). Now let's modify our `chat.py` script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e65703-dae5-4fbd-a9a1-b4c9290dce5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import aiohttp\n",
    "import asyncio\n",
    "\n",
    "API_URL = 'http://localhost:8000/v1/chat/completions'\n",
    "headers = {\"Content-Type\":\"application/json\"}\n",
    "\n",
    "payload = {\n",
    "\"max_tokens\":512,\n",
    "\"messages\": []\n",
    "}\n",
    "async def main():\n",
    "    while True:\n",
    "        prompt = input(\"User: \")\n",
    "        msg = {\n",
    "            \"content\": f\"{prompt} ### response: \",\n",
    "            \"role\": \"user\"\n",
    "        }\n",
    "        payload[\"messages\"].append(msg)\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            async with session.post(API_URL, data = json.dumps(payload), headers = headers) as resp:\n",
    "                reply = await resp.json()\n",
    "                reply_content = reply[\"choices\"][0][\"message\"][\"content\"]\n",
    "                print(f\"Bot: {reply_content}\")\n",
    "        msg_idx = payload[\"messages\"].index(message)\n",
    "        payload[\"messages\"][msg_idx][\"content\"] += reply_content\n",
    "\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf2cf5e-2ea9-42fc-94b7-a0cd87e5e5a2",
   "metadata": {},
   "source": [
    "First we took out payload out of the `while` loop (line 8 to 11), it has now an empty list in the `messages` field that we are going to fill with our conversation as it progresses.  \n",
    "We then created a `msg` variable (line 15) which is going to contain the prompt the user just typed. This `msg` will be then appended to the `payload`'s `messages` field (line 19). The rest of the code is similar and will proceed to give a response i.e `reply_content`.  Now we need to take this response and append its corresponding prompt in the `payload`'s `messages` field. We can do that by first getting the index of our actual message (line 25), then we will add that response to the prompt (line 26).  \n",
    "\n",
    "Now save and run the script again. We can now see that our model can keep up with us:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34fa263-921c-4b84-936b-66a159522305",
   "metadata": {},
   "source": [
    "```\n",
    "User: What is the largest city in Africa?\n",
    "Bot:  The largest city in Africa is Lagos, Nigeria. It has a population of over 20 million people, according to estimates in 2020.\n",
    "User: What is the second largest one?\n",
    "Bot:  The second largest city in Africa is Cairo, Egypt. It has a population of approximately 20 million people, according to estimates in 2020.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83140f74-909b-441d-8f82-eb0fad78a93d",
   "metadata": {},
   "source": [
    "Now we are good to go. Let's put everything together and create a Discord Bot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c30460-e9ef-4f56-a891-ce44cd80c26e",
   "metadata": {},
   "source": [
    "# 3. Putting everything together:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a881e2a-0ded-4ea7-a35d-1330e4a87f24",
   "metadata": {},
   "source": [
    "## 3.1 Creating a Discord App:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f69187d-c819-44a0-94e9-4d9f1b70851e",
   "metadata": {},
   "source": [
    "- Go to this link [https://discord.com/developers/applications](https://discord.com/developers/applications)\n",
    "- Log in or create a new account if you don't have any.\n",
    "- Click on New Application (Top Right) \n",
    "- Provide a Name to your app.\n",
    "- Accept the terms\n",
    "- Click Create  \n",
    "\n",
    "Now in the `General Information` give a name to your bot and a description if you desire, you can also upload a profile picture for it.  \n",
    "\n",
    "- Click Save Changes  \n",
    "\n",
    "Now on the left go to `Bot` section  \n",
    "\n",
    "- Click on `Reset Token` button (confirm the message)\n",
    "- Click `Copy` to copy it  \n",
    "\n",
    "Now go back to your project directory and create a new file called `.env` and paste your token in it with `TOKEN=` in the beginning.  \n",
    "You `.env` file should look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3462e4f8-fe73-405e-bff6-e24161668c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN=<HERE IS WHERE YOU WILL PAST YOUR TOKEN>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d49671-c92c-481a-900b-718b02fefcf3",
   "metadata": {},
   "source": [
    "Save and close this file.  \n",
    "Now back on the Bot configuration page you need to changes two things:\n",
    "- Toggle off the Public Bot button.\n",
    "- Toggle on the `MESSAGE CONTENT INTENT` button.\n",
    "As shown here ![Screenshot](1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386c0c63-3db8-4397-a273-2c44976a3c77",
   "metadata": {},
   "source": [
    "Now go to the `OAuth2` tab, we need to generate a URL that will help us invite our bot to our server. \n",
    "- Go to `URL Generator` and tick the `bot` box.\n",
    "As shown in the following screenshot ![screenshot bot](2.png)\n",
    "- Now tick the following permissions:\n",
    "> - Send Messages\n",
    "> - Create Public Threads\n",
    "> - Create Private Threads\n",
    "> - Send Messages in Threads\n",
    "> - Send TTS Messages\n",
    "> - Read Message History\n",
    "> - Use External Emojis\n",
    "> - Use External Stickers\n",
    "> - Add Reactions\n",
    "\n",
    "As shown in the following screenshot ![screenshot permissions](3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a68725-f722-4dcb-b07c-3ccc7ef8e321",
   "metadata": {},
   "source": [
    "Now go to the bottom and copy the generated URL and open it in a new browser tab\n",
    "\n",
    "If this is your first time using Discrod, you must create a server to add your Bot to, you can do that by following this [tutorial](https://www.howtogeek.com/364075/how-to-create-set-up-and-manage-your-discord-server/).  \n",
    "Once you have a server in your account  \n",
    "- Open the generated URL copied previously in a new tab.  \n",
    "- Select your server.  \n",
    "![Screen server](4.png)  \n",
    "- Click Continue\n",
    "- Authorize the permissions again\n",
    "- Prove your Humanity! (easier said than done :( )  \n",
    "\n",
    "Now you are in the server with your bot!  \n",
    "![Screenshot server with bot](5.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fdfc7d-6d6f-4ddb-8860-2b95c8a5bfba",
   "metadata": {},
   "source": [
    "Our Discord Bot is created, now all we have left to do is to 'connect' it with our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3810ee5f-b95c-40e0-8341-6c0becca6832",
   "metadata": {},
   "source": [
    "## 3.2 LLM Discord Bot:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03105e1-9b61-46e3-a5e2-5a9712d3cbd6",
   "metadata": {},
   "source": [
    "Now we need to write a script that would connect our Discord Bot to our local LLM model.  \n",
    "\n",
    "Let's go back to the terminal and create a copy of the `chat.py` and name it `bot.py` because we will need most of the code we wrote previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9648de1d-40dd-4dfb-bea5-350f69512d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp chat.py bot.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bf8b8d-6bb6-428f-91ae-03c39bd259c8",
   "metadata": {},
   "source": [
    "- Open `bot.py`.  \n",
    "\n",
    "For the code of our bot we will use an example from `discord.py` repository which can be found in this link: [https://github.com/Rapptz/discord.py/blob/master/examples/reply.py](https://github.com/Rapptz/discord.py/blob/master/examples/reply.py)  \n",
    "\n",
    "- Copy all the code in `reply.py` and paste it at the end of your `bot.py` file  \n",
    "- Now move `import discord` to the top \n",
    "- Remove the original `asyncio.run(main())`\n",
    "- Remove the comment from the example.\n",
    "- Move all the code in the `while` loop under `await message.reply('Hello!', mention_author=True)` and indent it properly\n",
    "- Move `await message.reply('Hello!', mention_author=True)` under `print(f\"Bot: {reply_content}\")` and indent it properly\n",
    "- Delete `print(f\"Bot: {reply_content}\")`\n",
    "- Edit `await message.reply('Hello!', mention_author=True)` to `await message.reply(reply_content, mention_author=True)` \n",
    "- Delete the `async def main` function\n",
    "- In `if message.content.startswith('!hello'):` replace `!hello` with `!bot`\n",
    "- Replace`prompt = input(\"User: \")` with `stripped_msg = str(message.content).replace('!bot','').strip()`\n",
    "- Now in the `msg` variable, change `{prompt}` to `{stripped_mgs}`\n",
    "\n",
    "We are almost done, we need to add our token that we put in the `.env` file earlier, to do so we need to add the following code to the top of the file:  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bf8017-e8a0-42a7-a3e2-ba6739a11e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "TOKEN = os.getenv(\"TOKEN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e872f5c-ebfc-4a02-8a8b-614ab9a962b7",
   "metadata": {},
   "source": [
    "and at the end of the file edit `client.run('token')` to `client.run(TOKEN)`  \n",
    "Your `bot.py` file shoud look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578bd55e-6869-42a5-b90a-ef037a33e60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import aiohttp\n",
    "import asyncio\n",
    "import discord\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv \n",
    "load_dotenv()\n",
    "TOKEN = os.getenv(\"TOKEN\")\n",
    "\n",
    "API_URL = 'http://localhost:8000/v1/chat/completions'\n",
    "headers = {\"Content-Type\":\"application/json\"}\n",
    "\n",
    "payload = {\n",
    "    \"max_tokens\":512,\n",
    "    \"messages\": []\n",
    "}\n",
    "\n",
    "class MyClient(discord.Client):\n",
    "    async def on_ready(self):\n",
    "        print(f'Logged in as {self.user} (ID: {self.user.id})')\n",
    "        print('------')\n",
    "\n",
    "    async def on_message(self, message):\n",
    "        # we do not want the bot to reply to itself\n",
    "        if message.author.id == self.user.id:\n",
    "            return\n",
    "\n",
    "        if message.content.startswith('!bot'):\n",
    "            stripped_msg = str(message.content).replace('!bot','').strip()\n",
    "            msg = {\n",
    "                \"content\": f\"{stripped_msg} ### response: \",\n",
    "                \"role\": \"user\"\n",
    "            }\n",
    "            payload[\"messages\"].append(msg)\n",
    "            async with aiohttp.ClientSession() as session:\n",
    "                async with session.post(API_URL, data = json.dumps(payload), headers = headers) as resp:\n",
    "                    reply = await resp.json()\n",
    "                    reply_content = reply[\"choices\"][0][\"message\"][\"content\"]\n",
    "                    await message.reply(reply_content, mention_author=True)\n",
    "            msg_idx = payload[\"messages\"].index(msg)\n",
    "            payload[\"messages\"][msg_idx][\"content\"] += reply_content \n",
    "\n",
    "\n",
    "intents = discord.Intents.default()\n",
    "intents.message_content = True\n",
    "\n",
    "client = MyClient(intents=intents)\n",
    "client.run(TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15610207-30f6-4554-8e3c-d98a18abf37c",
   "metadata": {},
   "source": [
    "Save it and run it, you should a message like this in the terminal:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e313a289-a31d-4c11-b6cb-3ad75519d8c1",
   "metadata": {},
   "source": [
    "```\n",
    "2023-11-07 17:10:33 INFO     discord.client logging in using static token\n",
    "2023-11-07 17:10:34 INFO     discord.gateway Shard ID None has connected to Gateway (Session ID: ff89fsdf2342502081fe39).\n",
    "Logged in as llm-bot#8912 (ID: 1173453534535)\n",
    "------\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37dd61e5-fcaa-4286-a4f2-201816554c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "python bot.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca368555-a7fa-40bf-ade5-e43484a66bdf",
   "metadata": {},
   "source": [
    "Go back to your Discord Client, you will see that the bot is now `Online`.  \n",
    "To interact with the bot you must start your message with `!bot` that's the flag that will prompt the bot to answer.  \n",
    "\n",
    "Congratulations you have now a working LLM Discord Bot!  \n",
    "![final screenshot](6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4053202b-b93f-45d8-8033-638501cfb72f",
   "metadata": {},
   "source": [
    "You can find the code used in this tutorial in my [GitHub Repository](https://github.com/HaoES/discord-LLM-bot)  \n",
    "If you have any questions feel free to [Contact Me](mailto:hamza.essamaali@gmail.com)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
