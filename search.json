[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Hamza ES-SAMAALI",
    "section": "",
    "text": "I am currently a Data Science Professor at EMSI - Marrakech. I love learning as much as I love teaching. This blog is where I will be sharing my thoughts about Machine Learning related topics."
  },
  {
    "objectID": "posts/Why-this-blog/index.html",
    "href": "posts/Why-this-blog/index.html",
    "title": "Why Blogging? (and How?)",
    "section": "",
    "text": "I’ve had a complex relationship with blogging. I’ve always wanted to blog but found it too much of a hassle.\nThen I stumbled upon this post and decided to start my own blog documenting my journey as a Machine Learning enthusiast.\nThis blog will principally be a way for me to digest what I’ve learned (the best way of learning is teaching), share my thoughts and the projects I do.\nI had two main choices for blogging, the first is Medium and the second is through Github Pages.\nFor no explainable reason I never liked Medium maybe because of the annoying reading limit it has when it asks you to connect (I hold grudges easily). As for Github Pages, I found Jekyll too much of a pain to deal with, too lazy to learn its intricacies.\nFortunately this year I decided to start the famous fast.ai course and Jeremy kept talking about Quarto and how it generates blog posts from Jupyter Notebooks. I also stumbled upon this blog of a fellow fast.ai student and used his posts to create my own blog.\nSo let me share with you How I did it:"
  },
  {
    "objectID": "posts/Why-this-blog/index.html#installing-quarto-in-wsl",
    "href": "posts/Why-this-blog/index.html#installing-quarto-in-wsl",
    "title": "Why Blogging? (and How?)",
    "section": "Installing Quarto in WSL",
    "text": "Installing Quarto in WSL\nto install Quarto in WSL (or Ubuntu) via nbdev use:\nmamba install -c fastchan nbdev  \nnbdev_install_quarto"
  },
  {
    "objectID": "posts/coriander-parsley-classifier/index.html",
    "href": "posts/coriander-parsley-classifier/index.html",
    "title": "A coriander قزبر vs معدنوس Parsley Classifier",
    "section": "",
    "text": "Coriander قزبر and parsley معدنوس are two staple ingredients of Moroccan cuisine, our moms have the superpower of easily distinguishing between them, but us mortals cannot.\nIn lesson 2 of Deep Learning for Coders 2022 part 1, Jeremy presented a simple image classification model for grizzly, black and teddy bears. I will be using a similar model to help us on this strenuous and confusing task."
  },
  {
    "objectID": "posts/coriander-parsley-classifier/index.html#create-a-huggingface-account",
    "href": "posts/coriander-parsley-classifier/index.html#create-a-huggingface-account",
    "title": "A coriander قزبر vs معدنوس Parsley Classifier",
    "section": "2.1 Create a HuggingFace Account",
    "text": "2.1 Create a HuggingFace Account\n\nVisit HuggingFace Website and Create an account\nNow go to HuggingFace Spaces and Create a New Space\nIn the SDK section select Gradio\n\n\nYou have now a new space.\n\nGo to your terminal in install git lfs (to be able to upload large files) using the following command:\ngit lfs install\nNow clone your space to your computer using the command:\ngit clone https://huggingface.co/spaces/<your_username>/<your_spacename>"
  },
  {
    "objectID": "posts/coriander-parsley-classifier/index.html#creating-a-gradio-app",
    "href": "posts/coriander-parsley-classifier/index.html#creating-a-gradio-app",
    "title": "A coriander قزبر vs معدنوس Parsley Classifier",
    "section": "2.2 Creating a Gradio app",
    "text": "2.2 Creating a Gradio app\nNow we should create a Gradio app that takes an input from the user and queries the model for its prediction and return it.\nGradio usually requires a python file named app.py but we will be doing things differently.\nIn the fastai course we used JupyterNotebooks and nbdev to create such file, to do so, create a new Jupyter Notebook (in the folder of your cloned repo) and fill the first cell with this code:\n\n#<add a pipe character here>default_exp app\n\n#|default_exp app\nNow let’s import fastai vision and gradio\n\n#<add a pipe character here>export\nfrom fastai.vision.all import *\nimport gradio as gr\n\nthe first comment in the cell should be #|default_exp app, it is is an indicator for nbdev to export the file and name it “app”. The rest is imports we will need.\nNow move the exported model.pkl model to the folder of your repo and load it.\n\n#<add a pipe character here>export\nlearn = load_learner('model.pkl')\n\nthat #|export line indicates to nbdev that the code of this cell needs to be included in the final exported app.py, if you want to do some tests for example import some images and try the model on them you can do so on cells that do not have the comment on their first line.\nOur model is now up and ready, let’s create a Gradio interface:\n\n#<add a pipe character here>export\ncategories = ('coriander', 'parsley')\ndef classify_image(img):\n    pred, idx, probs = learn.predict(img)\n    return dict(zip(categories,map(float,probs)))\n\nLet’s break this down a bit:\n- categories contains the categories that our classifier chooses from.\nGradio requires us to give him a function that he will call, this function is classify_image, it takes an image as an arguments. the learner has a method predict that takes an input and returns 3 things:\n- pred: True for positive class, False for negative class\n- idx: gives the index of the class\n- probs: gives the probability that this item is in this class for example if we have two categories probs will be a (2,1) array with probs[0] the probability of the item being in class 0, and probs[1] the probability of it being in class 1.\nThe function returns a dictionary with categories as keys and float(probs) as values, if you are not familiar with the dict(zip()) paradigm, check up this video.\nNow that we have our function set, let’s go and create the actual interface:\n\n#<add a pipe character here>export\nimage = gr.inputs.Image(shape=(192,192))\nlabel = gr.outputs.Label()\nexamples = ['coriander.jpg','parsley.jpg']\n\nintf = gr.Interface(fn=classify_image, inputs = image, outputs = label, examples = examples)\nintf.launch(inline=False)\n\nWe created an image input object and a label output object. We also added two images to our main folder of actual coriander and parsley respectively named coriander.jpg and parsley.jpg.\nThen we proceed to creating an interface that takes as parameters:\n- fn: the function classify_image\n- inputs: the input image\n- outputs: the output label\n- examples: this is optional, use it if you want to add examples to help the user.\nOur notebook is ready to be converted into a Gradio app! We will use nbdev to do so add this cell to the bottom of your notebook and run it:\n\nimport nbdev\nnbdev.export.nb_export('app.ipynb', 'app')\nprint('Export successful')\n\nWe are almost done, all we need to do now is to create a requirements.txt file and fill it with the following:\nfastai  \ntorch  \ngradio  \nEverything is good now, let’s push this to HuggingFace:\nYou can either do this from the terminal (reminder: make sure to install git lfs) using the following commands:\ngit add .\ngit commit -m \"add your custom message\"\ngit push\nOr via the HuggingFace Website, Go to your space -> Files and versions. And add your files manually from there.\nWhen everything is done, visit https://huggingface.co/spaces/<your_username>/<your_spacename> and you will have a fully operational coriander and parsley classifying app that you can share with your friends, it’s not perfect but still it’s better than wild guessing.\nHere is mine\nNote: Hugging Face Spaces that run on the default cpu-basic hardware (free tier), will go to sleep if inactive for more than a set time (currently, 72 hours). Anyone visiting your Space will restart it automatically. When it goes to sleep you can restart it by going to your spaces."
  },
  {
    "objectID": "posts/understanding-gradient-descent/index.html",
    "href": "posts/understanding-gradient-descent/index.html",
    "title": "Understanding Gradient Descent",
    "section": "",
    "text": "As you know I am currently doing fast.ai course. And I decided to take my time doing Lesson 3 because it’s about a very important topic: “Gradient Descent”.\nI’ve done many ML courses by the past (Andrew Ng’s Course, Aurelien Geron’s book, etc…) and each of these helped me understand what gradient descent was to a certain extent. But now I can confidently say that I’ve finally grasped what Gradient Descent is truly about.\nYou too can achieve the same understanding by following the steps I did:\n\nWatch the lesson 3 video and follow with Jeremy\nRead Chapter 4 of the fastai book\nWatch Andrej Karpathy’s amazing video: The spelled-out intro to neural networks and backpropagation: building micrograd\n\nI can’t stress enough how amazing Andrej’s video is!!! It’s a perfect complementary material to fast.ai’s lesson 3, and he goes step by step on how to build micrograd which is an autograd engine.\nDon’t forget to write the code along with both Jeremy and Andrej.\nDo this and you will have understood how Gradient Descent works and you will know how to implement it too."
  },
  {
    "objectID": "posts/fastai-deep-learning-for-coders-part-1/index.html",
    "href": "posts/fastai-deep-learning-for-coders-part-1/index.html",
    "title": "Summing up fastai’s Deep Learning for Coders Part 1",
    "section": "",
    "text": "In the ever-evolving world of artificial intelligence, deep learning has emerged as a powerful tool for solving complex problems. However, getting started with deep learning can be a daunting task, especially for coders without prior experience in this field. Fast.ai’s Practical Deep Learning for Coders course, offers an accessible and hands-on approach to learning deep learning concepts. In this blog post, we’ll explore the first part of the course, highlighting its key elements and sharing the invaluable insights gained from this immersive learning experience.\n\nA Practical Approach to Learning Deep Learning:\nFast.ai’s approach to teaching deep learning is unique. Instead of diving straight into the theory and mathematics behind neural networks, the course focuses on hands-on coding exercises and real-world applications. This approach enables coders to build and deploy their own deep learning models from day one, fostering a deeper understanding of the underlying concepts.\n\n\nFastai Library: Simplifying Deep Learning:\nAt the core of the course is the fastai library, a high-level deep learning framework built on top of PyTorch. This library abstracts away much of the complexity associated with training neural networks, making it easier for coders to experiment with different architectures and techniques. With its comprehensive set of pre-built functions, the fastai library allows learners to rapidly prototype and iterate their models.\n\n\nImage Classification and Data Augmentation:\nThe first part of the course delves into image classification, a fundamental problem in computer vision. Through a series of engaging lessons and coding exercises, learners are introduced to concepts such as convolutional neural networks (CNNs) and transfer learning. Moreover, the course emphasizes the importance of data augmentation techniques, enabling learners to improve model performance by generating synthetic training data. Jeremy also gives a plethora of advises regarding both the training and data augmentation phases.\n\n\nCollaborative Filtering and Natural Language Processing:\nBeyond computer vision, the course also covers collaborative filtering and natural language processing (NLP). With collaborative filtering, learners gain insights into recommender systems, enabling them to build personalized recommendation engines. In the NLP section, participants learn how to process and analyze text data using techniques like tokenization, language modeling, and sentiment analysis. These topics broaden the scope of the course, demonstrating the versatility of deep learning in various domains.\n\n\nLive Coding Session:\nDo not forget the “hidden” and most important part in my opinion of this amazing course: The live coding sessions. Jeremy walks you through how he went through a kaggle competition to get to the first place while explaining how to setup a proper working environment for kaggle competition and deep learning in general. YOU SHOULD NOT MISS THIS!!!\n\n\nConclusion:\nFast.ai’s Practical Deep Learning for Coders - Part 1 offers a remarkable entry point into the world of deep learning for coders. Through its hands-on approach, practical examples, and emphasis on real-world applications, the course equips learners with the necessary skills to build and deploy deep learning models. By leveraging the power of the fastai library and gaining a deep understanding of fundamental concepts, participants develop the confidence to explore and experiment with various domains within deep learning. If you’re a coder interested in venturing into the exciting realm of deep learning, Fast.ai’s course is undoubtedly an excellent starting point on your journey."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Hamza's Blog",
    "section": "",
    "text": "Summing up fastai’s Deep Learning for Coders Part 1\n\n\n\n\n\n\n\nfastai\n\n\nml\n\n\n\n\n\n\n\n\n\n\n\nJul 8, 2023\n\n\nHamza ES-SAMAALI\n\n\n\n\n\n\n  \n\n\n\n\nUnderstanding Gradient Descent\n\n\n\n\n\n\n\ngradient\n\n\ndescent\n\n\nneural\n\n\nnetwork\n\n\n\n\n\n\n\n\n\n\n\nApr 3, 2023\n\n\nHamza ES-SAMAALI\n\n\n\n\n\n\n  \n\n\n\n\nA coriander قزبر vs معدنوس Parsley Classifier\n\n\n\n\n\n\n\nfastai\n\n\nml\n\n\nclassification\n\n\n\n\n\n\n\n\n\n\n\nFeb 8, 2023\n\n\nHamza\n\n\n\n\n\n\n  \n\n\n\n\nWhy Blogging? (and How?)\n\n\n\n\n\n\n\nblogging\n\n\nquarto\n\n\njupyter\n\n\nfastai\n\n\n\n\n\n\n\n\n\n\n\nFeb 3, 2023\n\n\nHamza Es-samaali\n\n\n\n\n\n\nNo matching items"
  }
]